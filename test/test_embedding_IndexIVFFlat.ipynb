{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"../data/pubmed_baseline/csv/pubmed25n1274.csv\" \n",
    "df = pl.read_csv(csv_path)\n",
    "print(f'Number of rows: {len(df)}')\n",
    "\n",
    "columns_to_check = [\"PMID\", \"Title\", \"Abstract\", \"Authors\", \"Year\", \"Journal\"]\n",
    "df = df.drop_nulls(subset=columns_to_check)\n",
    "print(f'Number of rows after dropping nulls: {len(df)}')\n",
    "\n",
    "df = df.with_columns(df[\"Year\"].cast(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"abhinand/MedEmbed-base-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(device).eval()\n",
    "model = model.half()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"Title\"] + \". \" + df[\"Abstract\"]\n",
    "\n",
    "def embed_text_in_batches(texts, batch_size=32):\n",
    "    texts = list(texts)  # Ensure texts is a list\n",
    "    all_embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing Batches\"):\n",
    "        batch_texts = texts[i:i+batch_size]  # Directly slice the list\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].to(torch.float32).cpu().numpy()  # Use CLS token\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "\n",
    "        del inputs, outputs  # Release memory\n",
    "        torch.cuda.empty_cache()  # Clear GPU memory\n",
    "\n",
    "    return np.vstack(all_embeddings)  # Combine all batch results\n",
    "\n",
    "# Generate embeddings for all texts\n",
    "embeddings = embed_text_in_batches(texts, batch_size=9000)  # If still OutOfMemory, change batch_size to 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up FAISS vector index\n",
    "d = embeddings.shape[1]  # Vector dimension\n",
    "N = embeddings.shape[0]  # Number of embeddings\n",
    "nlist = min(int(4 * np.sqrt(N)), N)  # Number of clusters\n",
    "quantizer = faiss.IndexFlatL2(d)  # Quantizer with L2 distance\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\n",
    "\n",
    "# Train FAISS index (IVF requires training)\n",
    "index.train(embeddings)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FAISS index\n",
    "faiss.write_index(index, \"faiss_medical_index_IndexIVFFlat.ivf\")\n",
    "\n",
    "# Save metadata\n",
    "df.write_csv(\"faiss_metadata_IndexIVFFlat.csv\")\n",
    "\n",
    "print(\"Vector index built and saved FAISS index and Metadata!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/louis900412/anaconda3/envs/rag/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"abhinand/MedEmbed-base-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(device).eval()\n",
    "\n",
    "index = faiss.read_index(\"../output/2020/faiss.index\")\n",
    "\n",
    "df = pd.read_csv(\"../output/2020/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ 1. Deep learning-assisted survival prognosis in renal cancer: A CT scan-based personalized approach. (2024)\n",
      "    üìù Abstract: This paper presents a deep learning (DL) approach for predicting survival probabilities of renal cancer patients based solely on preoperative CT imaging. The proposed approach consists of two networks: a classifier- and a survival- network. The classifier attempts to extract features from 3D CT scans to predict the ISUP grade of Renal cell carcinoma (RCC) tumors, as defined by the International Society of Urological Pathology (ISUP). Our classifier is a 3D convolutional neural network to avoid losing crucial information on the interconnection of slides in 3D images. We employ multiple procedures, including image augmentation, preprocessing, and concatenation, to improve the performance of the classifier. Given the strong correlation between ISUP grading and renal cancer prognosis in the clinical context, we use the ISUP grading features extracted by the classifier as the input to the survival network. By leveraging this clinical association and the classifier network, we are able to model our survival analysis using a simple DL-based network. We adopt a discrete LogisticHazard-based loss to extract intrinsic survival characteristics of RCC tumors from CT images. This allows us to build a completely parametric survival model that varies with patients' tumor characteristics and predicts non-proportional survival probability curves for different patients. Our results demonstrated that the proposed method could predict the future course of renal cancer with reasonable accuracy from the CT scans. The proposed method obtained an average concordance index of 0.72, an integrated Brier score of 0.15, and an area under the curve value of 0.71 on the test cohorts.\n",
      "    üë©‚Äç‚öïÔ∏è Authors: Maryamalsadat Mahootiha, Hemin Ali Qadir, Davit Aghayan, √Ösmund Avdem Fretland, Bj√∏rn von Gohren Edwin, Ilangko Balasingham\n",
      "    üè• Journal: Heliyon\n",
      "    üîë Keywords: Cancer prognosis&Deep learning&Imaging biomarkers&Kidney tumor grading&Personalized prognosis&Radiomics&Renal cell carcinoma&Survival analysis\n",
      "    üîó PMID: 38298725\n",
      "\n",
      "üîπ 2. Spherical Convolutional Neural Networks for Survival Rate Prediction in Cancer Patients. (2022)\n",
      "    üìù Abstract: Survival Rate Prediction (SRP) is a valuable tool to assist in the clinical diagnosis and treatment planning of lung cancer patients. In recent years, deep learning (DL) based methods have shown great potential in medical image processing in general and SRP in particular. This study proposes a fully-automated method for SRP from computed tomography (CT) images, which combines an automatic segmentation of the tumor and a DL-based method for extracting rotational-invariant features.\n",
      "    üë©‚Äç‚öïÔ∏è Authors: Fabian Sinzinger, Mehdi Astaraki, √ñrjan Smedby, Rodrigo Moreno\n",
      "    üè• Journal: Frontiers in oncology\n",
      "    üîë Keywords: Cox Proportional Hazards&DeepSurv&deep learning&lung cancer&spherical convolutional neural network&survival rate prediction&tumor segmentation\n",
      "    üîó PMID: 35574400\n",
      "\n",
      "üîπ 3. Imaging-Based Deep Graph Neural Networks for Survival Analysis in Early Stage Lung Cancer Using CT: A Multicenter Study. (2022)\n",
      "    üìù Abstract: Lung cancer is the leading cause of cancer-related mortality, and accurate prediction of patient survival can aid treatment planning and potentially improve outcomes. In this study, we proposed an automated system capable of lung segmentation and survival prediction using graph convolution neural network (GCN) with CT data in non-small cell lung cancer (NSCLC) patients.\n",
      "    üë©‚Äç‚öïÔ∏è Authors: Jie Lian, Yonghao Long, Fan Huang, Kei Shing Ng, Faith M Y Lee, David C L Lam, Benjamin X L Fang, Qi Dou, Varut Vardhanabhuti\n",
      "    üè• Journal: Frontiers in oncology\n",
      "    üîë Keywords: cox proportional-hazards&graph convolutional networks&lung cancer&lung graph model&survival prediction\n",
      "    üîó PMID: 35936706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# **Search Function**\n",
    "def search_papers(query, top_k=5):\n",
    "    # **Step 1: Vectorize the query**\n",
    "    inputs = tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    query_embedding = outputs.last_hidden_state[:, 0, :].to(torch.float32).cpu().numpy()\n",
    "\n",
    "    # **Step 2: FAISS search**\n",
    "    D, I = index.search(query_embedding, top_k)  # D is the distance, I is the index\n",
    "\n",
    "    # **Step 3: Retrieve metadata based on indices**\n",
    "    results = df.iloc[I[0]].copy()  # Select the retrieved papers\n",
    "\n",
    "    # **Step 4: Sort by year (newest to oldest)**\n",
    "    results = results.sort_values(by=\"Year\", ascending=False)\n",
    "\n",
    "    # **Step 5: Format the output**\n",
    "    search_results = []\n",
    "    for _, row in results.iterrows():\n",
    "        search_results.append({\n",
    "            \"PMID\": row[\"PMID\"],\n",
    "            \"Title\": row[\"Title\"],\n",
    "            \"Abstract\": row[\"Abstract\"],\n",
    "            \"Authors\": row[\"Authors\"],\n",
    "            \"Year\": row[\"Year\"],\n",
    "            \"Journal\": row[\"Journal\"],\n",
    "            \"Keyword\": row[\"Keyword\"]\n",
    "        })\n",
    "\n",
    "    return search_results\n",
    "\n",
    "# **Test Search**\n",
    "query = \"Survival analysis using deep learning in medical imaging\"\n",
    "results = search_papers(query, top_k=3)\n",
    "\n",
    "# **Display results**\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"üîπ {i+1}. {res['Title']} ({res['Year']})\")\n",
    "    print(f\"    üìù Abstract: {res['Abstract']}\")\n",
    "    print(f\"    üë©‚Äç‚öïÔ∏è Authors: {res['Authors']}\")\n",
    "    print(f\"    üè• Journal: {res['Journal']}\")\n",
    "    print(f\"    üîë Keywords: {res['Keyword']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_retrieved_docs(search_results):\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(search_results):\n",
    "        title = doc.get(\"Title\", \"Unknown Title\")\n",
    "        abstract = doc.get(\"Abstract\", \"No abstract available.\")\n",
    "        context += f\"Document {i+1}:\\nTitle: {title}\\nAbstract: {abstract}\\n\\n\"\n",
    "    return context\n",
    "\n",
    "def generate_rag_prompt(query, search_results):\n",
    "    context = format_retrieved_docs(search_results)\n",
    "    \n",
    "    prompt = f\"\"\"You are a medical expert with extensive knowledge in deep learning applications for medical imaging and survival analysis.\n",
    "        The user has asked the following question:\n",
    "        \"{query}\"\n",
    "\n",
    "        Below are relevant research articles retrieved from PubMed:\n",
    "\n",
    "        {context}\n",
    "\n",
    "        Your task is to analyze the retrieved documents and generate a structured response. Follow these guidelines:\n",
    "\n",
    "        1. **Summarize each article** individually, extracting the key findings and methodologies.\n",
    "        2. **Highlight the relevance** of each study to the user's question.\n",
    "        3. **Compare methodologies**, identifying differences and potential synergies across papers.\n",
    "        4. **Provide a final synthesis**, explaining how these studies contribute to the overall understanding of the topic.\n",
    "        5. **If necessary, incorporate your expert knowledge**, but ensure that the response remains grounded in the retrieved literature.\n",
    "\n",
    "        ### **Response Format:**\n",
    "        **Article 1: [Title] ([Year])**  \n",
    "        (Summary: Key findings, methodology, and relevance)  \n",
    "\n",
    "        **Article 2: [Title] ([Year])**  \n",
    "        (Summary: Key findings, methodology, and relevance)  \n",
    "\n",
    "        **Article 3: [Title] ([Year])**  \n",
    "        (Summary: Key findings, methodology, and relevance)  \n",
    "\n",
    "        ### **Final Synthesis & Key Takeaways**\n",
    "        - (Compare methodologies across studies)\n",
    "        - (Discuss any common trends or contradictions)\n",
    "        - (Explain implications for clinical practice or research)\n",
    "\n",
    "        **Ensure that your response is precise, well-structured, and scientifically rigorous.**\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Title: Deep learning-assisted survival prognosis in renal cancer: A CT scan-based personalized approach. (2024)\n",
      "Document 2:\n",
      "Title: Spherical Convolutional Neural Networks for Survival Rate Prediction in Cancer Patients. (2022)\n",
      "Document 3:\n",
      "Title: Imaging-Based Deep Graph Neural Networks for Survival Analysis in Early Stage Lung Cancer Using CT: A Multicenter Study. (2022)\n",
      "\n",
      "===============================\n",
      "\n",
      "**Article 1: Deep learning-assisted survival prognosis in renal cancer: A CT scan-based personalized approach**  \n",
      "(Summary: Key findings, methodology, and relevance)  \n",
      "This study presents a deep learning approach designed to predict the survival probabilities of renal cancer patients based on preoperative CT imaging. The method employs two networks: a classifier network and a survival network. The classifier network, a 3D convolutional neural network, is tasked with extracting features from 3D CT scans to predict the ISUP grade of Renal cell carcinoma tumors. The ISUP grading features extracted by the classifier are then used as the input to the survival network. This approach managed to build a completely parametric survival model, predicting non-proportional survival probability curves for different patients. The method obtained a reasonable accuracy, demonstrating its potential in aiding survival prognosis in renal cancer. \n",
      "\n",
      "**Article 2: Spherical Convolutional Neural Networks for Survival Rate Prediction in Cancer Patients**  \n",
      "(Summary: Key findings, methodology, and relevance)  \n",
      "The research article proposes a fully-automated method for survival rate prediction from computed tomography (CT) images. The method utilizes an automatic segmentation of the tumor and a deep learning-based method to extract rotational-invariant features. This method makes use of spherical convolutional neural networks to predict survival rates in cancer patients, showing the potential of deep learning in medical image processing and in survival rate prediction.\n",
      "\n",
      "**Article 3: Imaging-Based Deep Graph Neural Networks for Survival Analysis in Early Stage Lung Cancer Using CT: A Multicenter Study**  \n",
      "(Summary: Key findings, methodology, and relevance)  \n",
      "This study presents an automated system that uses a graph convolution neural network (GCN) with CT data in non-small cell lung cancer (NSCLC) patients. The system is capable of lung segmentation and survival prediction, showing potential in aiding treatment planning and potentially improving outcomes.\n",
      "\n",
      "### **Final Synthesis & Key Takeaways**\n",
      "- All three studies utilize deep learning techniques to predict survival probabilities or rates based on CT images, showing the potential for the application of deep learning in medical imaging.\n",
      "- The first and second studies both employ convolutional neural networks, but with different approaches - the first uses a 3D convolutional neural network and a classifier network to predict renal cancer survival, while the second uses a spherical convolutional neural network for survival rate prediction in cancer patients.\n",
      "- The third study uses a graph convolution neural network for survival analysis in lung cancer patients.\n",
      "- These studies demonstrate the potential of deep learning in aiding the prediction of patient survival rates and probabilities, which can assist in treatment planning and potentially improve patient outcomes.\n",
      "- The differences in methodologies across the studies suggest that there may be potential synergies in combining these approaches to further improve the accuracy of survival predictions.\n",
      "- Further research is needed to evaluate the clinical implications and the impact of these methods on patient outcomes.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "for i, paper in enumerate(results):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"Title: {paper.get('Title', 'MISSING TITLE')} ({paper.get('Year', 'N/A')})\")\n",
    "\n",
    "print(\"\\n===============================\\n\")\n",
    "prompt = generate_rag_prompt(query, results)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in kidney ultrasound analysis.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "generated_answer = response.choices[0].message.content\n",
    "print(generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
