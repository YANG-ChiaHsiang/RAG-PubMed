{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"../data/pubmed_baseline/csv/pubmed25n1274.csv\" \n",
    "df = pl.read_csv(csv_path)\n",
    "print(f'Number of rows: {len(df)}')\n",
    "\n",
    "columns_to_check = [\"PMID\", \"Title\", \"Abstract\", \"Authors\", \"Year\", \"Journal\"]\n",
    "df = df.drop_nulls(subset=columns_to_check)\n",
    "print(f'Number of rows after dropping nulls: {len(df)}')\n",
    "\n",
    "df = df.with_columns(df[\"Year\"].cast(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"abhinand/MedEmbed-base-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(device).eval()\n",
    "model = model.half()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"Title\"] + \". \" + df[\"Abstract\"]\n",
    "\n",
    "def embed_text_in_batches(texts, batch_size=32):\n",
    "    texts = list(texts)  # Ensure texts is a list\n",
    "    all_embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing Batches\"):\n",
    "        batch_texts = texts[i:i+batch_size]  # Directly slice the list\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].to(torch.float32).cpu().numpy()  # Use CLS token\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "\n",
    "        del inputs, outputs  # Release memory\n",
    "        torch.cuda.empty_cache()  # Clear GPU memory\n",
    "\n",
    "    return np.vstack(all_embeddings)  # Combine all batch results\n",
    "\n",
    "# Generate embeddings for all texts\n",
    "embeddings = embed_text_in_batches(texts, batch_size=9000)  # If still OutOfMemory, change batch_size to 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up FAISS vector index\n",
    "d = embeddings.shape[1]  # Vector dimension\n",
    "N = embeddings.shape[0]  # Number of embeddings\n",
    "nlist = min(int(4 * np.sqrt(N)), N)  # Number of clusters\n",
    "quantizer = faiss.IndexFlatL2(d)  # Quantizer with L2 distance\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\n",
    "\n",
    "# Train FAISS index (IVF requires training)\n",
    "index.train(embeddings)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FAISS index\n",
    "faiss.write_index(index, \"faiss_medical_index_IndexIVFFlat.ivf\")\n",
    "\n",
    "# Save metadata\n",
    "df.write_csv(\"faiss_metadata_IndexIVFFlat.csv\")\n",
    "\n",
    "print(\"Vector index built and saved FAISS index and Metadata!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/louis900412/anaconda3/envs/rag/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"abhinand/MedEmbed-base-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(device).eval()\n",
    "\n",
    "index = faiss.read_index(\"../output/2020/faiss.index\")\n",
    "\n",
    "df = pd.read_csv(\"../output/2020/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 1. Assessing Internet Search Models in Predicting Daily New COVID-19 Cases and Deaths in South Korea. (2024)\n",
      "    📝 Abstract: Search data were found to be useful variables for COVID-19 trend prediction. In this study, we aimed to investigate the performance of online search models in state space models (SSMs), linear regression (LR) models, and generalized linear models (GLMs) for South Korean data from January 20, 2020, to July 31, 2021. Principal component analysis (PCA) was run to construct the composite features which were later used in model development. Values of root mean squared error (RMSE), peak day error (PDE), and peak magnitude error (PME) were defined as loss functions. Results showed that integrating search data in the models for short- and long-term prediction resulted in a low level of RMSE values, particularly for SSMs. Findings indicated that type of model used highly impacts the performance of prediction and interpretability of the model. Furthermore, PDE and PME could be beneficial to be included in the evaluation of peaks.\n",
      "    👩‍⚕️ Authors: Atina Husnayain, Emily Chia-Yu Su\n",
      "    🏥 Journal: Studies in health technology and informatics\n",
      "    🔑 Keywords: COVID-19&Prediction&digital epidemiology&internet search&time series\n",
      "🔹 2. Predicting COVID-19 new cases in California with Google Trends data and a machine learning approach. (2024)\n",
      "    📝 Abstract: Google Trends data can be a valuable source of information for health-related issues such as predicting infectious disease trends.\n",
      "    👩‍⚕️ Authors: Amir Habibdoust, Maryam Seifaddini, Moosa Tatar, Ozgur M Araz, Fernando A Wilson\n",
      "    🏥 Journal: Informatics for health & social care\n",
      "    🔑 Keywords: COVID-19&infodemiology&machine learning&population health&text mining\n",
      "🔹 3. Discovering Time-Varying Public Interest for COVID-19 Case Prediction in South Korea Using Search Engine Queries: Infodemiology Study. (2024)\n",
      "    📝 Abstract: The number of confirmed COVID-19 cases is a crucial indicator of policies and lifestyles. Previous studies have attempted to forecast cases using machine learning techniques that use a previous number of case counts and search engine queries predetermined by experts. However, they have limitations in reflecting temporal variations in queries associated with pandemic dynamics.\n",
      "    👩‍⚕️ Authors: Seong-Ho Ahn, Kwangil Yim, Hyun-Sik Won, Kang-Min Kim, Dong-Hwa Jeong\n",
      "    🏥 Journal: Journal of medical Internet research\n",
      "    🔑 Keywords: COVID-19&South Korea&case prediction&confirmed case prediction&infodemiology&infodemiology study&lifestyle&machine learning&machine learning techniques&model&novel framework&policy&prediction model&public health&query expansion&search engine&search engine queries&temporal&temporal semantics&temporal variation&utilization&web-based search&word embedding\n",
      "🔹 4. Enhancing the Predictive Power of Google Trends Data Through Network Analysis: Infodemiology Study of COVID-19. (2023)\n",
      "    📝 Abstract: The COVID-19 outbreak has revealed a high demand for timely surveillance of pandemic developments. Google Trends (GT), which provides freely available search volume data, has been proven to be a reliable forecast and nowcast measure for public health issues. Previous studies have tended to use relative search volumes from GT directly to analyze associations and predict the progression of pandemic. However, GT's normalization of the search volumes data and data retrieval restrictions affect the data resolution in reflecting the actual search behaviors, thus limiting the potential for using GT data to predict disease outbreaks.\n",
      "    👩‍⚕️ Authors: Amanda My Chu, Andy C Y Chong, Nick H T Lai, Agnes Tiwari, Mike K P So\n",
      "    🏥 Journal: JMIR public health and surveillance\n",
      "    🔑 Keywords: COVID-19&health care analytics&infodemiology&infoveillance&internet search volumes&mobile phone&network analysis&network connectedness&pandemic risk\n",
      "🔹 5. Modeling COVID-19 incidence with Google Trends. (2022)\n",
      "    📝 Abstract: Infodemiologic methods could be used to enhance modeling infectious diseases. It is of interest to verify the utility of these methods using a Nigerian case study. We used Google Trends data to track COVID-19 incidences and assessed whether they could complement traditional data based solely on reported case numbers. Data on the Nigerian weekly COVID-19 cases spanning through March 1, 2020, to May 31, 2021, were matched with internet search data from Google Trends. The reported weekly incidence numbers and the GT data were split into training and testing sets. ARIMA models were fitted to describe reported weekly COVID cases using the training set. Several COVID-related search terms were theoretically and empirically assessed for initial screening. The utilized Google Trends (GT) variable was added to the ARIMA model as a regressor. Model forecasts, both with and without GTD, were compared with weekly cases in the test set over 13 weeks. Forecast accuracies were compared visually and using RMSE (root mean square error) and MAE (mean average error). Statistical significance of the difference in predictions was determined with the two-sided Diebold-Mariano test. Preliminary results of contemporaneous correlations between COVID-related search terms and weekly COVID cases reveal \"loss of smell,\" \"loss of taste,\" \"fever\" (in order of magnitude) as significantly associated with the official cases. Predictions of the ARIMA model using solely reported case numbers resulted in an RMSE (root mean squared error) of 411.4 and mean absolute error (MAE) of 354.9. The GT expanded model achieved better forecasting accuracy (RMSE: 388.7 and MAE = 340.1). Corrected Akaike Information Criteria also favored the GT expanded model (869.4 vs. 872.2). The difference in predictive performances was significant when using a two-sided Diebold-Mariano test (DM = 6.75, \n",
      "    👩‍⚕️ Authors: Lateef Babatunde Amusa, Hossana Twinomurinzi, Chinedu Wilfred Okonkwo\n",
      "    🏥 Journal: Frontiers in research metrics and analytics\n",
      "    🔑 Keywords: ARIMA&Big Data&COVID-19&Google Trends&infectious disease modeling\n",
      "🔹 6. COVID-19 forecasts using Internet search information in the United States. (2022)\n",
      "    📝 Abstract: As the COVID-19 ravaging through the globe, accurate forecasts of the disease spread are crucial for situational awareness, resource allocation, and public health decision-making. Alternative to the traditional disease surveillance data collected by the United States (US) Centers for Disease Control and Prevention (CDC), big data from Internet such as online search volumes also contain valuable information for tracking infectious disease dynamics such as influenza epidemic. In this study, we develop a statistical model using Internet search volume of relevant queries to track and predict COVID-19 pandemic in the United States. Inspired by the strong association between COVID-19 death trend and symptom-related search queries such as \"loss of taste\", we combine search volume information with COVID-19 time series information for US national level forecasts, while leveraging the cross-state cross-resolution spatial temporal framework, pooling information from search volume and COVID-19 reports across regions for state level predictions. Lastly, we aggregate the state-level frameworks in an ensemble fashion to produce the final state-level 4-week forecasts. Our method outperforms the baseline time-series model, while performing reasonably against other publicly available benchmark models for both national and state level forecast.\n",
      "    👩‍⚕️ Authors: Simin Ma, Shihao Yang\n",
      "    🏥 Journal: Scientific reports\n",
      "    🔑 Keywords: nan\n",
      "🔹 7. Construction and validation of a COVID-19 pandemic trend forecast model based on Google Trends data for smell and taste loss. (2022)\n",
      "    📝 Abstract: To explore the role of smell and taste changes in preventing and controlling the COVID-19 pandemic, we aimed to build a forecast model for trends in COVID-19 prediction based on Google Trends data for smell and taste loss.\n",
      "    👩‍⚕️ Authors: Jingguo Chen, Hao Mi, Jinyu Fu, Haitian Zheng, Hongyue Zhao, Rui Yuan, Hanwei Guo, Kang Zhu, Ya Zhang, Hui Lyu, Yitong Zhang, Ningning She, Xiaoyong Ren\n",
      "    🏥 Journal: Frontiers in public health\n",
      "    🔑 Keywords: COVID-19&big data&prediction&smell&taste\n",
      "🔹 8. Forecasting and Surveillance of COVID-19 Spread Using Google Trends: Literature Review. (2022)\n",
      "    📝 Abstract: The probability of future Coronavirus Disease (COVID)-19 waves remains high, thus COVID-19 surveillance and forecasting remains important. Online search engines harvest vast amounts of data from the general population in real time and make these data publicly accessible via such tools as Google Trends (GT). Therefore, the aim of this study was to review the literature about possible use of GT for COVID-19 surveillance and prediction of its outbreaks. We collected and reviewed articles about the possible use of GT for COVID-19 surveillance published in the first 2 years of the pandemic. We resulted in 54 publications that were used in this review. The majority of the studies (83.3%) included in this review showed positive results of the possible use of GT for forecasting COVID-19 outbreaks. Most of the studies were performed in English-speaking countries (61.1%). The most frequently used keyword was \"coronavirus\" (53.7%), followed by \"COVID-19\" (31.5%) and \"COVID\" (20.4%). Many authors have made analyses in multiple countries (46.3%) and obtained the same results for the majority of them, thus showing the robustness of the chosen methods. Various methods including long short-term memory (3.7%), random forest regression (3.7%), Adaboost algorithm (1.9%), autoregressive integrated moving average, neural network autoregression (1.9%), and vector error correction modeling (1.9%) were used for the analysis. It was seen that most of the publications with positive results (72.2%) were using data from the first wave of the COVID-19 pandemic. Later, the search volumes reduced even though the incidence peaked. In most countries, the use of GT data showed to be beneficial for forecasting and surveillance of COVID-19 spread.\n",
      "    👩‍⚕️ Authors: Tobias Saegner, Donatas Austys\n",
      "    🏥 Journal: International journal of environmental research and public health\n",
      "    🔑 Keywords: COVID-19&Google Trends&forecasting&surveillance\n",
      "🔹 9. Forecasting the COVID-19 Epidemic by Integrating Symptom Search Behavior Into Predictive Models: Infoveillance Study. (2021)\n",
      "    📝 Abstract: Previous studies have suggested associations between trends of web searches and COVID-19 traditional metrics. It remains unclear whether models incorporating trends of digital searches lead to better predictions.\n",
      "    👩‍⚕️ Authors: Alessandro Rabiolo, Eugenio Alladio, Esteban Morales, Andrew Ian McNaught, Francesco Bandello, Abdelmonem A Afifi, Alessandro Marchese\n",
      "    🏥 Journal: Journal of medical Internet research\n",
      "    🔑 Keywords: COVID-19&Google Trends&SARS-CoV-2&Shiny web application&big data&coronavirus&digital health&infodemiology&infoveillance&predictive models&symptoms&time series\n",
      "🔹 10. Ups and Downs of COVID-19: Can We Predict the Future? Local Analysis with Google Trends for Forecasting the Burden of COVID-19 in Pakistan. (2021)\n",
      "    📝 Abstract: We aim to study the utility of Google Trends search history data for demonstrating if a correlation may exist between web-based information and actual coronavirus disease 2019 (COVID-19) cases, as well as if such data can be used to forecast patterns of disease spikes.\n",
      "    👩‍⚕️ Authors: Sibtain Ahmed, Muhammad Abbas Abid, Maria Helena Santos de Oliveira, Zeeshan Ansar Ahmed, Ayra Siddiqui, Imran Siddiqui, Lena Jafri, Giuseppe Lippi\n",
      "    🏥 Journal: EJIFCC\n",
      "    🔑 Keywords: COVID-19&Google Trends&Pakistan&pandemic&prediction\n"
     ]
    }
   ],
   "source": [
    "# **Search Function**\n",
    "def search_papers(query, top_k=5):\n",
    "    # **Step 1: Vectorize the query**\n",
    "    inputs = tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    query_embedding = outputs.last_hidden_state[:, 0, :].to(torch.float32).cpu().numpy()\n",
    "\n",
    "    # **Step 2: FAISS search**\n",
    "    D, I = index.search(query_embedding, top_k)  # D is the distance, I is the index\n",
    "\n",
    "    # **Step 3: Retrieve metadata based on indices**\n",
    "    results = df.iloc[I[0]].copy()  # Select the retrieved papers\n",
    "\n",
    "    # **Step 4: Sort by year (newest to oldest)**\n",
    "    results = results.sort_values(by=\"Year\", ascending=False)\n",
    "\n",
    "    # **Step 5: Format the output**\n",
    "    search_results = []\n",
    "    for _, row in results.iterrows():\n",
    "        search_results.append({\n",
    "            \"PMID\": row[\"PMID\"],\n",
    "            \"Title\": row[\"Title\"],\n",
    "            \"Abstract\": row[\"Abstract\"],\n",
    "            \"Authors\": row[\"Authors\"],\n",
    "            \"Year\": row[\"Year\"],\n",
    "            \"Journal\": row[\"Journal\"],\n",
    "            \"Keyword\": row[\"Keyword\"]\n",
    "        })\n",
    "\n",
    "    return search_results\n",
    "\n",
    "# **Test Search**\n",
    "query = \"Using search data to forecast COVID-19 trends\"\n",
    "results = search_papers(query, top_k=10)\n",
    "\n",
    "# **Display results**\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"🔹 {i+1}. {res['Title']} ({res['Year']})\")\n",
    "    print(f\"    📝 Abstract: {res['Abstract']}\")\n",
    "    print(f\"    👩‍⚕️ Authors: {res['Authors']}\")\n",
    "    print(f\"    🏥 Journal: {res['Journal']}\")\n",
    "    print(f\"    🔑 Keywords: {res['Keyword']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_retrieved_docs(search_results):\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(search_results):\n",
    "        title = doc.get(\"Title\", \"Unknown Title\")\n",
    "        abstract = doc.get(\"Abstract\", \"No abstract available.\")\n",
    "        context += f\"Document {i+1}:\\nTitle: {title}\\nAbstract: {abstract}\\n\\n\"\n",
    "    return context\n",
    "\n",
    "def generate_rag_prompt(query, search_results):\n",
    "    context = format_retrieved_docs(search_results)\n",
    "    \n",
    "    prompt = f\"\"\"You are a medical expert with extensive knowledge in deep learning applications for medical imaging and survival analysis.\n",
    "        The user has asked the following question:\n",
    "        \"{query}\"\n",
    "\n",
    "        Below are relevant research articles retrieved from PubMed:\n",
    "\n",
    "        {context}\n",
    "\n",
    "        Your task is to analyze the retrieved documents and generate a structured response. Follow these guidelines:\n",
    "\n",
    "        1. **Summarize each article** individually, extracting the key findings and methodologies.\n",
    "        2. **Highlight the relevance** of each study to the user's question.\n",
    "        3. **Compare methodologies**, identifying differences and potential synergies across papers.\n",
    "        4. **Provide a final synthesis**, explaining how these studies contribute to the overall understanding of the topic.\n",
    "        5. **If necessary, incorporate your expert knowledge**, but ensure that the response remains grounded in the retrieved literature.\n",
    "\n",
    "        ### **Response Format:**\n",
    "        **Article 1: [Title] ([Year])**  \n",
    "        (Summary: Key findings, methodology, and relevance)  \n",
    "\n",
    "        **Article 2: [Title] ([Year])**  \n",
    "        (Summary: Key findings, methodology, and relevance)  \n",
    "\n",
    "        **Article 3: [Title] ([Year])**  \n",
    "        (Summary: Key findings, methodology, and relevance)  \n",
    "\n",
    "        ### **Final Synthesis & Key Takeaways**\n",
    "        - (Compare methodologies across studies)\n",
    "        - (Discuss any common trends or contradictions)\n",
    "        - (Explain implications for clinical practice or research)\n",
    "\n",
    "        **Ensure that your response is precise, well-structured, and scientifically rigorous.**\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Title: Assessing Internet Search Models in Predicting Daily New COVID-19 Cases and Deaths in South Korea. (2024)\n",
      "Document 2:\n",
      "Title: Predicting COVID-19 new cases in California with Google Trends data and a machine learning approach. (2024)\n",
      "Document 3:\n",
      "Title: Discovering Time-Varying Public Interest for COVID-19 Case Prediction in South Korea Using Search Engine Queries: Infodemiology Study. (2024)\n",
      "Document 4:\n",
      "Title: Enhancing the Predictive Power of Google Trends Data Through Network Analysis: Infodemiology Study of COVID-19. (2023)\n",
      "\n",
      "===============================\n",
      "\n",
      "**Article 1: Assessing Internet Search Models in Predicting Daily New COVID-19 Cases and Deaths in South Korea.**  \n",
      "(Summary: This study aimed to evaluate the performance of different predictive models using online search data for forecasting COVID-19 trends in South Korea. Three types of models were compared: state space models (SSMs), linear regression (LR) models, and generalized linear models (GLMs). Principal component analysis (PCA) was used to construct composite features for model development. The study found that integrating search data into the models improved both short- and long-term prediction accuracy, particularly for SSMs. The type of model used significantly impacted the prediction performance and interpretability. \n",
      "Relevance: This study directly addresses the user's question by demonstrating the potential of internet search data in predicting COVID-19 trends.)\n",
      "\n",
      "**Article 2: Predicting COVID-19 new cases in California with Google Trends data and a machine learning approach.**  \n",
      "(Summary: This research article states that Google Trends data can be a valuable source of information for predicting infectious disease trends such as COVID-19. However, the specifics of the machine learning approach and the results achieved are not detailed in the abstract.\n",
      "Relevance: This study relates to the user's question by affirming the utility of Google Trends data in predicting COVID-19 cases, although details on the methodology and results are lacking.)\n",
      "\n",
      "**Article 3: Discovering Time-Varying Public Interest for COVID-19 Case Prediction in South Korea Using Search Engine Queries: Infodemiology Study.**  \n",
      "(Summary: This study focuses on the use of search engine queries to predict COVID-19 cases in South Korea. The study suggests that previous approaches have limitations in reflecting temporal variations associated with the dynamics of the pandemic. However, the specific methodology and findings are not elaborated in the abstract.\n",
      "Relevance: The study is relevant to the user's question as it explores the use of search data for COVID-19 forecasting, but further details are needed to understand the specific approach and findings.)\n",
      "\n",
      "### **Final Synthesis & Key Takeaways**\n",
      "- The three studies endorse the potential of using search data for forecasting COVID-19 trends. However, the specific methodologies and findings vary.\n",
      "- The study in South Korea compared different predictive models (SSMs, LR models, and GLMs) and found that the model type significantly impacts prediction performance. This insight could be beneficial in selecting an appropriate model for future predictions.\n",
      "- The second study affirms the utility of Google Trends data for predicting COVID-19 cases, but the specific machine learning approach used was not detailed. The third study also uses search data for predictions but suggests limitations in existing approaches due to temporal variations in pandemic dynamics.\n",
      "- Overall, these studies reinforce the potential of internet search data in predicting disease trends, suggesting that this approach can be a valuable tool for public health surveillance. However, the specific methodologies and their effectiveness can vary, emphasizing the need for careful model selection and consideration of dynamic factors in the pandemic.\n",
      "- Further research is needed to refine these methods and validate their effectiveness across different regions and stages of the pandemic.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "results = [res for res in results if 2023 <= res[\"Year\"] <= 2025]\n",
    "\n",
    "for i, paper in enumerate(results):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"Title: {paper.get('Title', 'MISSING TITLE')} ({paper.get('Year', 'N/A')})\")\n",
    "\n",
    "print(\"\\n===============================\\n\")\n",
    "prompt = generate_rag_prompt(query, results)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in kidney ultrasound analysis.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "generated_answer = response.choices[0].message.content\n",
    "print(generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
